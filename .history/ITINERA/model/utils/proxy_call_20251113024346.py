import requests
import json
import logging
import os

from openai import OpenAI

class OpenaiCall:
    def __init__(self, api_key=None, base_url=None):
        api_key = api_key or os.getenv("OPENAI_API_KEY")
        # Support multiple common env var names for base URL
        base_url = (
            base_url
            or os.getenv("OPENAI_BASE_URL")
            or os.getenv("OPENAI_API_BASE")
            or os.getenv("OPENAI_PROXY_BASE")
        )
        if base_url:
            self.client = OpenAI(api_key=api_key, base_url=base_url)
        else:
            self.client = OpenAI(api_key=api_key)

    def chat(self, messages, model="gpt-3.5-turbo-1106", temperature=0):
        # Allow overriding chat model via environment variable
        model = os.getenv("OPENAI_CHAT_MODEL", model)
        response = self.client.chat.completions.create(
            model=model,
            # response_format={"type": "json_object"},
            messages=messages,
            temperature=temperature
        )
        return response.choices[0].message.content

    def stream_chat(self, messages, model="gpt-3.5-turbo-1106", temperature=0):
        model = os.getenv("OPENAI_CHAT_MODEL", model)
        for chunk in self.client.chat.completions.create(
            model=model,
            # response_format={"type": "json_object"},
            messages=messages,
            temperature=temperature,
            stream=True
        ): 
            # Some providers may yield None chunks intermittently
            if getattr(chunk, "choices", None):
                delta = chunk.choices[0].delta
                content = getattr(delta, "content", None)
                if content is not None:
                    yield content
    
    def embedding(self, input_data, model=None):
        # Align default with offline embeddings generated by emb_gen.py
        # Can be overridden via env var OPENAI_EMBEDDING_MODEL
        model = model or os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-ada-002")
        response = self.client.embeddings.create(
            input=input_data,
            model=model
        )

        return response